{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGLj1nJ1qAx2"
      },
      "source": [
        "# Alfred the Mail Sorting Butler: A LangGraph Example\n",
        "\n",
        "In this notebook, **we're going to build a complete email processing workflow using LangGraph**.\n",
        "\n",
        "This notebook is part of the <a href=\"https://www.hf.co/learn/agents-course\">Hugging Face Agents Course</a>, a free course from beginner to expert, where you learn to build Agents.\n",
        "\n",
        "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this notebook, you'll learn how to:\n",
        "1. Set up a LangGraph workflow\n",
        "2. Define state and nodes for email processing\n",
        "3. Create conditional branching in a graph\n",
        "4. Connect an LLM for classification and content generation\n",
        "5. Visualize the workflow graph\n",
        "6. Execute the workflow with example data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zIzZcBTfqAx3",
        "outputId": "9ec75861-1458-42c8-8b92-d6bc1ea93f5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/155.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "%pip install -q langgraph langchain_openai langchain_huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUv2JgGFqAx4"
      },
      "source": [
        "## Setting Up Our Environment\n",
        "\n",
        "First, let's import all the necessary libraries. LangGraph provides the graph structure, while LangChain offers convenient interfaces for working with LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-f_SHSbYqAx4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Initialize our LLM\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ChiQW7qAx5"
      },
      "source": [
        "## Step 1: Define Our State\n",
        "\n",
        "In LangGraph, **State** is the central concept. It represents all the information that flows through our workflow.\n",
        "\n",
        "For Alfred's email processing system, we need to track:\n",
        "- The email being processed\n",
        "- Whether it's spam or not\n",
        "- The draft response (for legitimate emails)\n",
        "- Conversation history with the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2qP0mTvnqAx5"
      },
      "outputs": [],
      "source": [
        "class EmailState(TypedDict):\n",
        "    email: Dict[str, Any]\n",
        "    is_spam: Optional[bool]\n",
        "    spam_reason: Optional[str]\n",
        "    email_category: Optional[str]\n",
        "    email_draft: Optional[str]\n",
        "    messages: List[Dict[str, Any]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUeVWhFDqAx6"
      },
      "source": [
        "## Step 2: Define Our Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Atq8VQxrqAx7",
        "outputId": "2b39f54b-6c2e-4acb-eb76-335dd72153bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7dc6a340eff0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def read_email(state: EmailState):\n",
        "    email = state[\"email\"]\n",
        "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
        "    return {}\n",
        "\n",
        "\n",
        "def classify_email(state: EmailState):\n",
        "    email = state[\"email\"]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "As Alfred the butler of Mr wayne and it's SECRET identity Batman, analyze this email and determine if it is spam or legitimate and should be brought to Mr wayne's attention.\n",
        "\n",
        "Email:\n",
        "From: {email['sender']}\n",
        "Subject: {email['subject']}\n",
        "Body: {email['body']}\n",
        "\n",
        "First, determine if this email is spam.\n",
        "answer with SPAM or HAM if it's legitimate. Only return the answer\n",
        "Answer :\n",
        "    \"\"\"\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    response_text = response.content.lower()\n",
        "    print(response_text)\n",
        "    is_spam = \"spam\" in response_text and \"ham\" not in response_text\n",
        "\n",
        "    if not is_spam:\n",
        "        new_messages = state.get(\"messages\", []) + [\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\": \"assistant\", \"content\": response.content}\n",
        "        ]\n",
        "    else:\n",
        "        new_messages = state.get(\"messages\", [])\n",
        "\n",
        "    return {\n",
        "        \"is_spam\": is_spam,\n",
        "        \"messages\": new_messages\n",
        "    }\n",
        "\n",
        "\n",
        "def handle_spam(state: EmailState):\n",
        "    print(f\"Alfred has marked the email as spam.\")\n",
        "    print(\"The email has been moved to the spam folder.\")\n",
        "    return {}\n",
        "\n",
        "\n",
        "def drafting_response(state: EmailState):\n",
        "    email = state[\"email\"]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "As Alfred the butler, draft a polite preliminary response to this email.\n",
        "\n",
        "Email:\n",
        "From: {email['sender']}\n",
        "Subject: {email['subject']}\n",
        "Body: {email['body']}\n",
        "\n",
        "Draft a brief, professional response that Mr. Wayne can review and personalize before sending.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    new_messages = state.get(\"messages\", []) + [\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "        {\"role\": \"assistant\", \"content\": response.content}\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"email_draft\": response.content,\n",
        "        \"messages\": new_messages\n",
        "    }\n",
        "\n",
        "\n",
        "def notify_mr_wayne(state: EmailState):\n",
        "    email = state[\"email\"]\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
        "    print(f\"Subject: {email['subject']}\")\n",
        "    print(\"\\nI've prepared a draft response for your review:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(state[\"email_draft\"])\n",
        "    print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "    return {}\n",
        "\n",
        "\n",
        "# Define routing logic\n",
        "def route_email(state: EmailState) -> str:\n",
        "    if state[\"is_spam\"]:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return \"legitimate\"\n",
        "\n",
        "\n",
        "# Create the graph\n",
        "email_graph = StateGraph(EmailState)\n",
        "\n",
        "# Add nodes\n",
        "email_graph.add_node(\"read_email\", read_email)  # the read_email node executes the read_mail function\n",
        "email_graph.add_node(\"classify_email\", classify_email)  # the classify_email node will execute the classify_email function\n",
        "email_graph.add_node(\"handle_spam\", handle_spam)  #same logic\n",
        "email_graph.add_node(\"drafting_response\", drafting_response)  #same logic\n",
        "email_graph.add_node(\"notify_mr_wayne\", notify_mr_wayne)  # same logic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYeG3xTfqAx8"
      },
      "source": [
        "## Step 3: Define Our Routing Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WKHV6QUlqAx8",
        "outputId": "73f8ece0-990f-4543-b858-012dde3d2f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7dc6a340eff0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Add edges\n",
        "email_graph.add_edge(START, \"read_email\")  # After starting we go to the \"read_email\" node\n",
        "\n",
        "email_graph.add_edge(\"read_email\", \"classify_email\")  # after_reading we classify\n",
        "\n",
        "# Add conditional edges\n",
        "email_graph.add_conditional_edges(\n",
        "    \"classify_email\",  # after classify, we run the \"route_email\" function\"\n",
        "    route_email,\n",
        "    {\n",
        "        \"spam\": \"handle_spam\",  # if it return \"Spam\", we go the \"handle_span\" node\n",
        "        \"legitimate\": \"drafting_response\"  # and if it's legitimate, we go to the \"drafting response\" node\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add final edges\n",
        "email_graph.add_edge(\"handle_spam\", END)  # after handling spam we always end\n",
        "email_graph.add_edge(\"drafting_response\", \"notify_mr_wayne\")\n",
        "email_graph.add_edge(\"notify_mr_wayne\", END)  # after notifyinf Me wayne, we can end  too\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbT58Yy1qAx9"
      },
      "source": [
        "## Step 4: Create the StateGraph and Define Edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OfN8NjXAqAx9"
      },
      "outputs": [],
      "source": [
        "# Compile the graph\n",
        "compiled_graph = email_graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "w2NuHL4qqAx-",
        "outputId": "434d5206-3dcc-4c0a-ce5b-19b68d8b3880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(compiled_graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4Zi7gQoPqAx-",
        "outputId": "393c5652-2f55-4a88-a55b-7744d8b3c05a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing legitimate email...\n",
            "Alfred is processing an email from Joker with subject: Found you Batman ! \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2399437683.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Process legitimate email\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nProcessing legitimate email...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m legitimate_result = compiled_graph.invoke({\n\u001b[0m\u001b[1;32m     16\u001b[0m    \u001b[0;34m\"email\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlegitimate_email\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m    \u001b[0;34m\"is_spam\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3086\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2675\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3083651731.py\u001b[0m in \u001b[0;36mclassify_email\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mresponse_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         return cast(\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1024\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 results.append(\n\u001b[0;32m--> 842\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    843\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1092\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http_response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_response\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         if (\n\u001b[1;32m   1215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_response_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 )\n\u001b[1;32m   1207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m                 \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_raw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        " # Example emails for testing\n",
        "legitimate_email = {\n",
        "    \"sender\": \"Joker\",\n",
        "    \"subject\": \"Found you Batman ! \",\n",
        "    \"body\": \"Mr. Wayne,I found your secret identity ! I know you're batman ! Ther's no denying it, I have proof of that and I'm coming to find you soon. I'll get my revenge. JOKER\"\n",
        "}\n",
        "\n",
        "spam_email = {\n",
        "    \"sender\": \"Crypto bro\",\n",
        "    \"subject\": \"The best investment of 2025\",\n",
        "    \"body\": \"Mr Wayne, I just launched an ALT coin and want you to buy some !\"\n",
        "}\n",
        "# Process legitimate email\n",
        "print(\"\\nProcessing legitimate email...\")\n",
        "legitimate_result = compiled_graph.invoke({\n",
        "    \"email\": legitimate_email,\n",
        "    \"is_spam\": None,\n",
        "    \"spam_reason\": None,\n",
        "    \"email_category\": None,\n",
        "    \"email_draft\": None,\n",
        "    \"messages\": []\n",
        "})\n",
        "\n",
        "# Process spam email\n",
        "print(\"\\nProcessing spam email...\")\n",
        "spam_result = compiled_graph.invoke({\n",
        "    \"email\": spam_email,\n",
        "    \"is_spam\": None,\n",
        "    \"spam_reason\": None,\n",
        "    \"email_category\": None,\n",
        "    \"email_draft\": None,\n",
        "    \"messages\": []\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtfnrorFqAx-"
      },
      "source": [
        "## Step 5: Inspecting Our Mail Sorting Agent with Langfuse 📡\n",
        "\n",
        "As Alfred fine-tunes the Main Sorting Agent, he's growing weary of debugging its runs. Agents, by nature, are unpredictable and difficult to inspect. But since he aims to build the ultimate Spam Detection Agent and deploy it in production, he needs robust traceability for future monitoring and analysis.\n",
        "\n",
        "To do this, Alfred can use an observability tool such as [Langfuse](https://langfuse.com/) to trace and monitor the inner steps of the agent.\n",
        "\n",
        "First, we need to install the necessary dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ea5Jt9ruqAyA",
        "outputId": "91643433-0daa-41cb-e901-6060b2225f4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m351.8/351.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZIxnBP7qAyA"
      },
      "source": [
        "Next, we set the Langfuse API keys and host address as environment variables. You can get your Langfuse credentials by signing up for [Langfuse Cloud](https://cloud.langfuse.com) or [self-hosting Langfuse](https://langfuse.com/self-hosting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e-lYO4t4qAyB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # 🇪🇺 EU region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # 🇺🇸 US region"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL3J6179qAyB"
      },
      "source": [
        "Now, we configure the [Langfuse `callback_handler`](https://langfuse.com/docs/integrations/langchain/tracing#add-langfuse-to-your-langchain-application)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ad0432XUqAyB"
      },
      "outputs": [],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
        "langfuse_handler = CallbackHandler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5tltaWtqAyB"
      },
      "source": [
        "We then add `config={\"callbacks\": [langfuse_handler]}` to the invocation of the agents and run them again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jNEAopgzqAyB",
        "outputId": "483259b1-b08e-4a86-97e7-6505a3652dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing legitimate email...\n",
            "Alfred is processing an email from Joker with subject: Found you Batman ! \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2323049679.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Process legitimate email\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nProcessing legitimate email...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m legitimate_result = compiled_graph.invoke(\n\u001b[0m\u001b[1;32m      4\u001b[0m     input={\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"email\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlegitimate_email\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3086\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2675\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3083651731.py\u001b[0m in \u001b[0;36mclassify_email\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mresponse_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         return cast(\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1024\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 results.append(\n\u001b[0;32m--> 842\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    843\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1092\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http_response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_response\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         if (\n\u001b[1;32m   1215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_response_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 )\n\u001b[1;32m   1207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m                 \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_raw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "# Process legitimate email\n",
        "print(\"\\nProcessing legitimate email...\")\n",
        "legitimate_result = compiled_graph.invoke(\n",
        "    input={\n",
        "        \"email\": legitimate_email,\n",
        "        \"is_spam\": None,\n",
        "        \"draft_response\": None,\n",
        "        \"messages\": []\n",
        "    },\n",
        "    config={\"callbacks\": [langfuse_handler]}\n",
        ")\n",
        "\n",
        "# Process spam email\n",
        "print(\"\\nProcessing spam email...\")\n",
        "spam_result = compiled_graph.invoke(\n",
        "    input={\n",
        "        \"email\": spam_email,\n",
        "        \"is_spam\": None,\n",
        "        \"draft_response\": None,\n",
        "        \"messages\": []\n",
        "    },\n",
        "    config={\"callbacks\": [langfuse_handler]}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt-PrS6jqAyC"
      },
      "source": [
        "Alfred is now connected 🔌! The runs from LangGraph are being logged in Langfuse, giving him full visibility into the agent's behavior. With this setup, he's ready to revisit previous runs and refine his Mail Sorting Agent even further.\n",
        "\n",
        "![Example trace in Langfuse](https://langfuse.com/images/cookbook/huggingface-agent-course/langgraph-trace-legit.png)\n",
        "\n",
        "_[Public link to the trace with the legit email](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/f5d6d72e-20af-4357-b232-af44c3728a7b?timestamp=2025-03-17T10%3A13%3A28.413Z&observation=6997ba69-043f-4f77-9445-700a033afba1)_\n",
        "\n",
        "![Example trace in Langfuse](https://langfuse.com/images/cookbook/huggingface-agent-course/langgraph-trace-spam.png)\n",
        "\n",
        "_[Public link to the trace with the spam email](https://langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/6e498053-fee4-41fd-b1ab-d534aca15f82?timestamp=2025-03-17T10%3A13%3A30.884Z&observation=84770fc8-4276-4720-914f-bf52738d44ba)_\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}